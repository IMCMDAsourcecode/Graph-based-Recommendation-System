{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = '\\t'\n",
    "\n",
    "# Check if files exist and download otherwise\n",
    "files = ['/u1.base', '/u1.test', '/u.item', '/u.user']\n",
    "fname = dataset\n",
    "data_dir = 'data/' + fname\n",
    "\n",
    "download_dataset(fname, files, data_dir)\n",
    "\n",
    "dtypes = {\n",
    "    'u_nodes': np.int32, 'v_nodes': np.int32,\n",
    "    'ratings': np.float32, 'timestamp': np.float64}\n",
    "\n",
    "\n",
    "filename_train = '../../dataset/ml-100k/u1.base'\n",
    "filename_test = '../../dataset/ml-100k/u1.test'\n",
    "\n",
    "data_train = pd.read_csv(\n",
    "    filename_train, sep=sep, header=None,\n",
    "    names=['u_nodes', 'v_nodes', 'ratings', 'timestamp'], dtype=dtypes)\n",
    "\n",
    "data_test = pd.read_csv(\n",
    "    filename_test, sep=sep, header=None,\n",
    "    names=['u_nodes', 'v_nodes', 'ratings', 'timestamp'], dtype=dtypes)\n",
    "\n",
    "data_array_train = data_train.as_matrix().tolist()\n",
    "data_array_train = np.array(data_array_train)\n",
    "data_array_test = data_test.as_matrix().tolist()\n",
    "data_array_test = np.array(data_array_test)\n",
    "\n",
    "data_array = np.concatenate([data_array_train, data_array_test], axis=0)\n",
    "\n",
    "u_nodes_ratings = data_array[:, 0].astype(dtypes['u_nodes'])\n",
    "v_nodes_ratings = data_array[:, 1].astype(dtypes['v_nodes'])\n",
    "ratings = data_array[:, 2].astype(dtypes['ratings'])\n",
    "\n",
    "u_nodes_ratings, u_dict, num_users = map_data(u_nodes_ratings)\n",
    "v_nodes_ratings, v_dict, num_items = map_data(v_nodes_ratings)\n",
    "\n",
    "u_nodes_ratings, v_nodes_ratings = u_nodes_ratings.astype(np.int64), v_nodes_ratings.astype(np.int32)\n",
    "ratings = ratings.astype(np.float64)\n",
    "\n",
    "u_nodes = u_nodes_ratings\n",
    "v_nodes = v_nodes_ratings\n",
    "\n",
    "neutral_rating = -1  # int(np.ceil(np.float(num_classes)/2.)) - 1\n",
    "\n",
    "# assumes that ratings_train contains at least one example of every rating type\n",
    "rating_dict = {r: i for i, r in enumerate(np.sort(np.unique(ratings)).tolist())}\n",
    "\n",
    "labels = np.full((num_users, num_items), neutral_rating, dtype=np.int32)\n",
    "labels[u_nodes, v_nodes] = np.array([rating_dict[r] for r in ratings])\n",
    "\n",
    "for i in range(len(u_nodes)):\n",
    "    assert(labels[u_nodes[i], v_nodes[i]] == rating_dict[ratings[i]])\n",
    "\n",
    "labels = labels.reshape([-1])\n",
    "\n",
    "# number of test and validation edges, see cf-nade code\n",
    "\n",
    "num_train = data_array_train.shape[0]\n",
    "num_test = data_array_test.shape[0]\n",
    "num_val = int(np.ceil(num_train * 0.2))\n",
    "num_train = num_train - num_val\n",
    "\n",
    "pairs_nonzero = np.array([[u, v] for u, v in zip(u_nodes, v_nodes)])\n",
    "idx_nonzero = np.array([u * num_items + v for u, v in pairs_nonzero])\n",
    "\n",
    "for i in range(len(ratings)):\n",
    "    assert(labels[idx_nonzero[i]] == rating_dict[ratings[i]])\n",
    "\n",
    "idx_nonzero_train = idx_nonzero[0:num_train+num_val]\n",
    "idx_nonzero_test = idx_nonzero[num_train+num_val:]\n",
    "\n",
    "pairs_nonzero_train = pairs_nonzero[0:num_train+num_val]\n",
    "pairs_nonzero_test = pairs_nonzero[num_train+num_val:]\n",
    "\n",
    "# Internally shuffle training set (before splitting off validation set)\n",
    "rand_idx = range(len(idx_nonzero_train))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(rand_idx)\n",
    "idx_nonzero_train = idx_nonzero_train[rand_idx]\n",
    "pairs_nonzero_train = pairs_nonzero_train[rand_idx]\n",
    "\n",
    "idx_nonzero = np.concatenate([idx_nonzero_train, idx_nonzero_test], axis=0)\n",
    "pairs_nonzero = np.concatenate([pairs_nonzero_train, pairs_nonzero_test], axis=0)\n",
    "\n",
    "val_idx = idx_nonzero[0:num_val]\n",
    "train_idx = idx_nonzero[num_val:num_train + num_val]\n",
    "test_idx = idx_nonzero[num_train + num_val:]\n",
    "\n",
    "assert(len(test_idx) == num_test)\n",
    "\n",
    "val_pairs_idx = pairs_nonzero[0:num_val]\n",
    "train_pairs_idx = pairs_nonzero[num_val:num_train + num_val]\n",
    "test_pairs_idx = pairs_nonzero[num_train + num_val:]\n",
    "\n",
    "u_test_idx, v_test_idx = test_pairs_idx.transpose()\n",
    "u_val_idx, v_val_idx = val_pairs_idx.transpose()\n",
    "u_train_idx, v_train_idx = train_pairs_idx.transpose()\n",
    "\n",
    "# create labels\n",
    "train_labels = labels[train_idx]\n",
    "val_labels = labels[val_idx]\n",
    "test_labels = labels[test_idx]\n",
    "\n",
    "if testing:\n",
    "    u_train_idx = np.hstack([u_train_idx, u_val_idx])\n",
    "    v_train_idx = np.hstack([v_train_idx, v_val_idx])\n",
    "    train_labels = np.hstack([train_labels, val_labels])\n",
    "    # for adjacency matrix construction\n",
    "    train_idx = np.hstack([train_idx, val_idx])\n",
    "\n",
    "# make training adjacency matrix\n",
    "rating_mx_train = np.zeros(num_users * num_items, dtype=np.float32)\n",
    "rating_mx_train[train_idx] = labels[train_idx].astype(np.float32) + 1.\n",
    "rating_mx_train = sp.csr_matrix(rating_mx_train.reshape(num_users, num_items))\n",
    "\n",
    "class_values = np.sort(np.unique(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = r'|'\n",
    "movie_file = '../../dataset/ml-100k/u.item'\n",
    "movie_headers = ['movie id', 'movie title', 'release date', 'video release date',\n",
    "                 'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "                 'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                 'Thriller', 'War', 'Western']\n",
    "movie_df = pd.read_csv(movie_file, sep=sep, header=None,\n",
    "                       names=movie_headers, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_headers = movie_df.columns.values[6:]\n",
    "num_genres = genre_headers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-616e61f1aa3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_vec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movie id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_headers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# check if movie_id was listed in ratings file and therefore in mapping dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmovie_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mv_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'v_dict' is not defined"
     ]
    }
   ],
   "source": [
    "v_features = np.zeros((1682, num_genres), dtype=np.float32)\n",
    "for movie_id, g_vec in zip(movie_df['movie id'].values.tolist(), movie_df[genre_headers].values.tolist()):\n",
    "    # check if movie_id was listed in ratings file and therefore in mapping dictionary\n",
    "    if movie_id in v_dict.keys():\n",
    "        v_features[v_dict[movie_id], :] = g_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user features\n",
    "\n",
    "sep = r'|'\n",
    "users_file = 'data/' + dataset + '/u.user'\n",
    "users_headers = ['user id', 'age', 'gender', 'occupation', 'zip code']\n",
    "users_df = pd.read_csv(users_file, sep=sep, header=None,\n",
    "                       names=users_headers, engine='python')\n",
    "\n",
    "occupation = set(users_df['occupation'].values.tolist())\n",
    "\n",
    "age = users_df['age'].values\n",
    "age_max = age.max()\n",
    "\n",
    "gender_dict = {'M': 0., 'F': 1.}\n",
    "occupation_dict = {f: i for i, f in enumerate(occupation, start=2)}\n",
    "\n",
    "num_feats = 2 + len(occupation_dict)\n",
    "\n",
    "u_features = np.zeros((num_users, num_feats), dtype=np.float32)\n",
    "for _, row in users_df.iterrows():\n",
    "    u_id = row['user id']\n",
    "    if u_id in u_dict.keys():\n",
    "        # age\n",
    "        u_features[u_dict[u_id], 0] = row['age'] / np.float(age_max)\n",
    "        # gender\n",
    "        u_features[u_dict[u_id], 1] = gender_dict[row['gender']]\n",
    "        # occupation\n",
    "        u_features[u_dict[u_id], occupation_dict[row['occupation']]] = 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mingbo-env] *",
   "language": "python",
   "name": "conda-env-.conda-mingbo-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
